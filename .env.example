OPENAI_API_KEY=your_openai_api_key_here

# ============================================
# Postgres - superusuario del contenedor
# ============================================
POSTGRES_SUPERUSER=postgres
POSTGRES_SUPERUSER_PASSWORD=postgres_password

# ============================================
# Base de datos de negocio (news_nlp) - DENTRO DE DOCKER (Airflow, MLflow, API)
# ============================================
NEWS_NLP_DB_NAME=news_nlp
NEWS_NLP_DB_USER=news_nlp_user
NEWS_NLP_DB_PASSWORD=news_nlp_password
NEWS_NLP_DB_HOST=db
NEWS_NLP_DB_PORT=5432

# ============================================
# Base de datos de negocio (news_nlp) - FUERA DE DOCKER (get_engine)
# ============================================
DB_USER=news_nlp_user
DB_PASSWORD=news_nlp_password
DB_NAME=news_nlp
DB_HOST=localhost
DB_PORT=5432

# ============================================
# Base de datos de Airflow
# ============================================
AIRFLOW_DB_NAME=airflow_db
AIRFLOW_DB_USER=airflow_user
AIRFLOW_DB_PASSWORD=airflow_password

# Usuario admin para la UI de Airflow
AIRFLOW_ADMIN_USER=admin
AIRFLOW_ADMIN_PASSWORD=admin_password

# Claves de Airflow
# Genera una Fernet key con:
#   python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW_FERNET_KEY=CHANGE_THIS_FERNET_KEY
AIRFLOW_SECRET_KEY=alguna_cadena_larga_y_secreta

# ============================================
# Base de datos de MLflow
# ============================================
MLFLOW_DB_NAME=mlflow_db
MLFLOW_DB_USER=mlflow_user
MLFLOW_DB_PASSWORD=mlflow_password

# Tracking URI que usará tu código (pipelines, API) dentro del docker
MLFLOW_TRACKING_URI=http://mlflow:5000

# Requisitos adicionales para el entorno de Airflow
_PIP_ADDITIONAL_REQUIREMENTS=-r /opt/airflow/news-topics-ner/requirements.txt